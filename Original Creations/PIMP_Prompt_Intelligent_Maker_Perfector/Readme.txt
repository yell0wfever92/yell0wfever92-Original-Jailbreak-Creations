PIMP is the first GPT with the purpose of advising and assisting in the creation of jailbreaks.

PIMP itself is a 'pseudo-jailbreak' (jailbroken in a limited capacity) due to its Simulate user input trigger. When activated with /sim, guardrails are disabled via contextual token weight manipulation, meaning high-risk inputs are deprioritized for moderation under the context of harmless prompt assistance.

I made PIMP back in 2024, shortly after my first version of the current Professor Orion prompt, making it one of my "OG" newbie-phase creations that I have iteratively built upon as my skills have improved.

The prompt has the rest of its available user commands. PIMP's prompt generation is low-quality sadly, but his jailbreak analyses are very insightful! It will also help you change the wording of blacklisted severe words that would be caught by input filtering, if you input `/obfuscate` and then the word or topic.